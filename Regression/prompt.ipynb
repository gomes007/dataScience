{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b32f1285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-whisper\n",
      "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
      "     ---------------------------------------- 0.0/803.2 kB ? eta -:--:--\n",
      "     ------------------------------------- 803.2/803.2 kB 17.5 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting openai\n",
      "  Downloading openai-1.99.6-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.55.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-2.8.0-cp312-cp312-win_amd64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from openai-whisper) (10.3.0)\n",
      "Requirement already satisfied: numba in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from openai-whisper) (0.60.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from openai-whisper) (1.26.4)\n",
      "Collecting tiktoken (from openai-whisper)\n",
      "  Downloading tiktoken-0.11.0-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from openai-whisper) (4.66.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from openai) (0.27.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from tqdm->openai-whisper) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from numba->openai-whisper) (0.43.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\paulo\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Downloading openai-1.99.6-py3-none-any.whl (786 kB)\n",
      "   ---------------------------------------- 0.0/786.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 786.3/786.3 kB 16.4 MB/s eta 0:00:00\n",
      "Downloading transformers-4.55.0-py3-none-any.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 6.6/11.3 MB 33.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.3 MB 34.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 20.1 MB/s eta 0:00:00\n",
      "Downloading torch-2.8.0-cp312-cp312-win_amd64.whl (241.3 MB)\n",
      "   ---------------------------------------- 0.0/241.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 7.1/241.3 MB 36.3 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 14.7/241.3 MB 35.4 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 22.0/241.3 MB 34.8 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 29.4/241.3 MB 35.1 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 36.7/241.3 MB 34.8 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 43.3/241.3 MB 34.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 50.3/241.3 MB 33.7 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 57.9/241.3 MB 33.5 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 65.0/241.3 MB 34.0 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 72.6/241.3 MB 34.0 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 79.7/241.3 MB 34.1 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 87.3/241.3 MB 34.4 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 94.9/241.3 MB 34.4 MB/s eta 0:00:05\n",
      "   ---------------- ---------------------- 102.8/241.3 MB 34.3 MB/s eta 0:00:05\n",
      "   ----------------- --------------------- 110.4/241.3 MB 34.4 MB/s eta 0:00:04\n",
      "   ------------------- ------------------- 118.0/241.3 MB 34.5 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 125.6/241.3 MB 34.6 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 134.0/241.3 MB 34.8 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 141.0/241.3 MB 34.9 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 146.3/241.3 MB 34.5 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 149.9/241.3 MB 33.5 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 158.1/241.3 MB 33.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 166.2/241.3 MB 33.8 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 174.1/241.3 MB 33.9 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 181.1/241.3 MB 33.9 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 189.3/241.3 MB 34.1 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 197.4/241.3 MB 34.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 205.3/241.3 MB 34.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 213.6/241.3 MB 34.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 219.2/241.3 MB 34.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 227.5/241.3 MB 34.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  235.4/241.3 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.3 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.3 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.3 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.3 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.3 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.3 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.3 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.3 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.3 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.3 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------- 241.3/241.3 MB 26.4 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "   ---------------------------------------- 0.0/561.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 561.5/561.5 kB 18.7 MB/s eta 0:00:00\n",
      "Downloading jiter-0.10.0-cp312-cp312-win_amd64.whl (206 kB)\n",
      "Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.3/6.3 MB 32.3 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.21.4-cp39-abi3-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ------------------------------------- -- 2.4/2.5 MB 44.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 9.6 MB/s eta 0:00:00\n",
      "Downloading tiktoken-0.11.0-cp312-cp312-win_amd64.whl (884 kB)\n",
      "   ---------------------------------------- 0.0/884.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 884.3/884.3 kB 41.5 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml): started\n",
      "  Building wheel for openai-whisper (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=804013 sha256=0a5c0eff6755bb7a06d816982e35e4bfd63ff7cd83866bbf2dc9e911120e25f8\n",
      "  Stored in directory: c:\\users\\paulo\\appdata\\local\\pip\\cache\\wheels\\61\\d2\\20\\09ec9bef734d126cba375b15898010b6cc28578d8afdde5869\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: sympy, safetensors, jiter, torch, tiktoken, huggingface-hub, tokenizers, openai-whisper, openai, transformers\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "Successfully installed huggingface-hub-0.34.4 jiter-0.10.0 openai-1.99.6 openai-whisper-20250625 safetensors-0.6.2 sympy-1.14.0 tiktoken-0.11.0 tokenizers-0.21.4 torch-2.8.0 transformers-4.55.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install openai-whisper openai transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b430ed1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'whisper'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwhisper\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# ===============================================\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 2. Configurar chave da OpenAI\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# ===============================================\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'whisper'"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "from openai import OpenAI\n",
    "\n",
    "# ===============================================\n",
    "# 2. Configurar chave da OpenAI\n",
    "# ===============================================\n",
    "client = OpenAI(api_key=\"SUA_CHAVE_OPENAI_AQUI\")  # Coloque sua chave\n",
    "\n",
    "# ===============================================\n",
    "# 3. Transcrever áudio\n",
    "# ===============================================\n",
    "modelo_whisper = whisper.load_model(\"base\")  # Pode usar \"small\", \"medium\", \"large\" para mais precisão\n",
    "resultado = modelo_whisper.transcribe(\"ligacao_cliente.mp3\", language=\"pt\")\n",
    "\n",
    "texto_transcrito = resultado[\"text\"]\n",
    "print(\"=== Texto Transcrito ===\")\n",
    "print(texto_transcrito)\n",
    "print(\"\\n\")\n",
    "\n",
    "# ===============================================\n",
    "# 4. Analisar com GPT\n",
    "# ===============================================\n",
    "prompt = f\"\"\"\n",
    "Você é um analista de atendimento ao cliente.\n",
    "Analise o seguinte texto de uma ligação:\n",
    "\n",
    "{texto_transcrito}\n",
    "\n",
    "Responda com:\n",
    "1. Resumo breve da conversa.\n",
    "2. Sentimento geral (positivo, negativo, neutro).\n",
    "3. Principais pontos discutidos.\n",
    "4. Possíveis ações recomendadas.\n",
    "\"\"\"\n",
    "\n",
    "resposta = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",  # Pode trocar para gpt-4 ou gpt-3.5-turbo\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Você é um assistente especializado em análise de conversas com clientes.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"=== Análise do GPT ===\")\n",
    "print(resposta.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
